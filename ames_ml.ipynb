{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "n_jobs = 6\n",
    "cv = 5\n",
    "\n",
    "k_best = 200\n",
    "do_pca = True\n",
    "pca_n_components = 0.9\n",
    "\n",
    "scoring = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (1460, 81)\n",
      "Test data shape:  (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./house-prices-advanced-regression-techniques/train.csv')\n",
    "print('Train data shape: ', train_df.shape)\n",
    "\n",
    "test_df = pd.read_csv('./house-prices-advanced-regression-techniques/test.csv')\n",
    "print('Test data shape: ', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df['SalePrice']\n",
    "\n",
    "train_df.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 80)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat([train_df, test_df])\n",
    "\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle columns with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage      259\n",
       "Alley           1369\n",
       "MasVnrType         8\n",
       "MasVnrArea         8\n",
       "BsmtQual          37\n",
       "BsmtCond          37\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtFinType2      38\n",
       "Electrical         1\n",
       "FireplaceQu      690\n",
       "GarageType        81\n",
       "GarageYrBlt       81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "PoolQC          1453\n",
       "Fence           1179\n",
       "MiscFeature     1406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()[train_df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning           4\n",
       "LotFrontage      227\n",
       "Alley           1352\n",
       "Utilities          2\n",
       "Exterior1st        1\n",
       "Exterior2nd        1\n",
       "MasVnrType        16\n",
       "MasVnrArea        15\n",
       "BsmtQual          44\n",
       "BsmtCond          45\n",
       "BsmtExposure      44\n",
       "BsmtFinType1      42\n",
       "BsmtFinSF1         1\n",
       "BsmtFinType2      42\n",
       "BsmtFinSF2         1\n",
       "BsmtUnfSF          1\n",
       "TotalBsmtSF        1\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "KitchenQual        1\n",
       "Functional         2\n",
       "FireplaceQu      730\n",
       "GarageType        76\n",
       "GarageYrBlt       78\n",
       "GarageFinish      78\n",
       "GarageCars         1\n",
       "GarageArea         1\n",
       "GarageQual        78\n",
       "GarageCond        78\n",
       "PoolQC          1456\n",
       "Fence           1169\n",
       "MiscFeature     1408\n",
       "SaleType           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()[test_df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric features\n",
    "\n",
    "numeric_features_fill_mean = [ 'LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                             'TotalBsmtSF', 'GarageArea']\n",
    "\n",
    "for feature in numeric_features_fill_mean:\n",
    "    all_df[feature]=all_df[feature].fillna(all_df[feature].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_fill_mode = ['GarageYrBlt', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars']\n",
    "\n",
    "for feature in numeric_features_fill_mode:\n",
    "    all_df[feature]=all_df[feature].fillna(all_df[feature].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "\n",
    "categorical_features_fill_none = ['Alley', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                                 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', 'GarageType',\n",
    "                                 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
    "                                  'MiscFeature']\n",
    "\n",
    "for feature in categorical_features_fill_none:\n",
    "    all_df[feature]=all_df[feature].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_fill_mode = ['Electrical', 'MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd',\n",
    "                                 'KitchenQual', 'Functional', 'SaleType']\n",
    "\n",
    "for feature in categorical_features_fill_mode:\n",
    "    all_df[feature]=all_df[feature].fillna(all_df[feature].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df['Id']\n",
    "\n",
    "train_df.drop(['Id'],axis=1,inplace=True)\n",
    "test_df.drop(['Id'],axis=1,inplace=True)\n",
    "all_df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (1460, 79)\n",
      "Test data shape:  (1459, 79)\n",
      "All df data shape:  (2919, 79)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape: ', train_df.shape)\n",
    "print('Test data shape: ', test_df.shape)\n",
    "print('All df data shape: ', all_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummify categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 302)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.get_dummies(all_df)\n",
    "\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToBeDummified = pd.Series(\n",
    "    ['MSSubClass',\n",
    "    'OverallQual',\n",
    "    'OverallCond'])\n",
    "\n",
    "for col in colsToBeDummified:\n",
    "    dummies = pd.get_dummies(all_df[col], drop_first=True, prefix=col)\n",
    "    all_df[dummies.columns] = dummies\n",
    "    \n",
    "all_df.drop(colsToBeDummified, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "scaler = PowerTransformer()\n",
    "\n",
    "all_df = pd.DataFrame(scaler.fit_transform(all_df), columns=all_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df = all_df.iloc[:train_df.shape[0],:]\n",
    "all_test_df = all_df.iloc[train_df.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Train data shape:  (1460, 331)\n",
      "All Test data shape:  (1459, 331)\n",
      "All df data shape:  (2919, 331)\n"
     ]
    }
   ],
   "source": [
    "print('All Train data shape: ', all_train_df.shape)\n",
    "print('All Test data shape: ', all_test_df.shape)\n",
    "print('All df data shape: ', all_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:293: RuntimeWarning: invalid value encountered in sqrt\n",
      "  n_samples * X_means ** 2)\n",
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "fs = SelectKBest(score_func=f_regression, k=k_best)\n",
    "\n",
    "x_train = all_df.iloc[:train_df.shape[0],:]\n",
    "\n",
    "X_selected = fs.fit_transform(x_train, y_train)\n",
    "\n",
    "mask = fs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 200)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = []\n",
    "\n",
    "for bool, feature in zip(mask, all_df.columns):\n",
    "    if bool:\n",
    "        selected_features.append(feature)        \n",
    "\n",
    "selected_features_df = pd.DataFrame(all_df[selected_features])\n",
    "\n",
    "selected_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 131)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_features = []\n",
    "\n",
    "for bool, feature in zip(~mask, all_df.columns):\n",
    "    if bool:\n",
    "        other_features.append(feature)\n",
    "        \n",
    "other_features_df = pd.DataFrame(all_df[other_features])\n",
    "\n",
    "other_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = pca_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2919, 92)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rescaled = scaler.fit_transform(other_features_df)\n",
    "\n",
    "pca.fit(data_rescaled)\n",
    "\n",
    "reduced = pca.transform(data_rescaled)\n",
    "reduced_df = pd.DataFrame(reduced)\n",
    "\n",
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 292)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if do_pca:\n",
    "    selected_features_df = selected_features_df.join(reduced_df)\n",
    "\n",
    "selected_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_train_df = selected_features_df.iloc[:train_df.shape[0],:]\n",
    "reduced_test_df = selected_features_df.iloc[train_df.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Train data shape:  (1460, 292)\n",
      "Reduced Test data shape:  (1459, 292)\n",
      "All selected df data shape:  (2919, 292)\n"
     ]
    }
   ],
   "source": [
    "print('Reduced Train data shape: ', reduced_train_df.shape)\n",
    "print('Reduced Test data shape: ', reduced_test_df.shape)\n",
    "print('All selected df data shape: ', selected_features_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressor=xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [250, 500, 750, 1000]\n",
    "max_depth = [5, 7, 10, 12]\n",
    "booster = ['gbtree','gblinear']\n",
    "learning_rate = [0.05,0.1,0.15]\n",
    "min_child_weight = [1,2,3]\n",
    "base_score = [0.25,0.5,0.75,1]\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'learning_rate': learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster': booster,\n",
    "    'base_score': base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv = model_selection.RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=parameters,\n",
    "            cv=cv, n_iter=50,\n",
    "            scoring = scoring,n_jobs = n_jobs,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  3.6min\n"
     ]
    }
   ],
   "source": [
    "random_cv.fit(reduced_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_pred = random_cv.predict(reduced_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Id': test_id, 'SalePrice': xbg_pred}\n",
    "submission_df = pd.DataFrame.from_dict(data)\n",
    "submission_df.to_csv('xgb_sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import sklearn\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import initializers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = reduced_train_df.shape[0]\n",
    "num_features     = reduced_train_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "start = time.time()\n",
    "tf.set_random_seed(random_state)\n",
    "\n",
    "kernel_initializer = initializers.TruncatedNormal(mean=0.0,stddev=0.1)\n",
    "bias_initializer   = initializers.Constant(0.1)\n",
    "    \n",
    "model.add(Dense(num_features*2, input_dim=num_features, input_shape=(num_features,),\n",
    "                activation=tf.nn.relu, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_features, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Dense(num_features/2, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_features/4, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units=1, activation=tf.nn.relu))\n",
    "\n",
    "adam = Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(loss=root_mean_squared_error, optimizer=adam)\n",
    "\n",
    "model.fit(reduced_train_df, y_train, epochs=1000, batch_size=10, verbose=0)\n",
    "\n",
    "print('Time elapsed: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = model.predict(reduced_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sales_price = []\n",
    "\n",
    "for price in nn_pred:\n",
    "    pred_sales_price.append(price[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Id': test_id, 'SalePrice': pred_sales_price}\n",
    "submission_df = pd.DataFrame.from_dict(data)\n",
    "submission_df.to_csv('nn_sample_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
